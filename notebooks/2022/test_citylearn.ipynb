{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c9f0479-0149-4a89-b45f-1d9fa1b99889",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2903233b-7d4b-4e39-9adb-c2ec7eee3df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5 * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9ac5da6-e044-4d59-af46-8e802599e19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a gym env\n",
    "#imple iter\n",
    "#kload schemas\n",
    "'''\n",
    "see obs\n",
    "see action space\n",
    "see render\n",
    "think how to SA it\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba50f83-d4cf-4831-bfe5-860921a2e428",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/intelligent-environments-lab/CityLearn/blob/citylearn_2022/challenge/agent.py\n",
    "#maybe useful for central agent stuff?\n",
    "\n",
    "\n",
    "# https://gitlab.aicrowd.com/aicrowd/challenges/citylearn-challenge-2022/citylearn-2022-starter-kit/-/blob/master/local_evaluation.py\n",
    "\n",
    "# import numpy as np\n",
    "# import time\n",
    "\n",
    "# \"\"\"\n",
    "# Please do not make changes to this file. \n",
    "# This is only a reference script provided to allow you \n",
    "# to do local evaluation. The evaluator **DOES NOT** \n",
    "# use this script for orchestrating the evaluations. \n",
    "# \"\"\"\n",
    "\n",
    "# from agents.orderenforcingwrapper import OrderEnforcingAgent\n",
    "# from citylearn.citylearn import CityLearnEnv\n",
    "\n",
    "# class Constants:\n",
    "#     episodes = 3\n",
    "#     schema_path = './data/citylearn_challenge_2022_phase_1/schema.json'\n",
    "\n",
    "# def action_space_to_dict(aspace):\n",
    "#     \"\"\" Only for box space \"\"\"\n",
    "#     return { \"high\": aspace.high,\n",
    "#              \"low\": aspace.low,\n",
    "#              \"shape\": aspace.shape,\n",
    "#              \"dtype\": str(aspace.dtype)\n",
    "#     }\n",
    "\n",
    "# def env_reset(env):\n",
    "#     observations = env.reset()\n",
    "#     action_space = env.action_space\n",
    "#     action_space_dicts = [action_space_to_dict(asp) for asp in action_space]\n",
    "#     obs_dict = {\"action_space\": action_space_dicts,\n",
    "#                 \"observation\": observations }\n",
    "#     return obs_dict\n",
    "\n",
    "# def evaluate():\n",
    "#     print(\"Starting local evaluation\")\n",
    "    \n",
    "#     env = CityLearnEnv(schema=Constants.schema_path)\n",
    "#     agent = OrderEnforcingAgent()\n",
    "\n",
    "#     obs_dict = env_reset(env)\n",
    "\n",
    "#     agent_time_elapsed = 0\n",
    "\n",
    "#     step_start = time.perf_counter()\n",
    "#     actions = agent.register_reset(obs_dict)\n",
    "#     agent_time_elapsed += time.perf_counter()- step_start\n",
    "\n",
    "#     episodes_completed = 0\n",
    "#     num_steps = 0\n",
    "#     interrupted = False\n",
    "#     episode_metrics = []\n",
    "#     try:\n",
    "#         while True:\n",
    "#             observations, _, done, _ = env.step(actions)\n",
    "#             if done:\n",
    "#                 episodes_completed += 1\n",
    "#                 metrics_t = env.evaluate()\n",
    "#                 metrics = {\"price_cost\": metrics_t[0], \"emmision_cost\": metrics_t[1]}\n",
    "#                 if np.any(np.isnan(metrics_t)):\n",
    "#                     raise ValueError(\"Episode metrics are nan, please contant organizers\")\n",
    "#                 episode_metrics.append(metrics)\n",
    "#                 print(f\"Episode complete: {episodes_completed} | Latest episode metrics: {metrics}\", )\n",
    "\n",
    "#                 obs_dict = env_reset(env)\n",
    "\n",
    "#                 step_start = time.perf_counter()\n",
    "#                 actions = agent.register_reset(obs_dict)\n",
    "#                 agent_time_elapsed += time.perf_counter()- step_start\n",
    "#             else:\n",
    "#                 step_start = time.perf_counter()\n",
    "#                 actions = agent.compute_action(observations)\n",
    "#                 agent_time_elapsed += time.perf_counter()- step_start\n",
    "            \n",
    "#             num_steps += 1\n",
    "#             if num_steps % 1000 == 0:\n",
    "#                 print(f\"Num Steps: {num_steps}, Num episodes: {episodes_completed}\")\n",
    "\n",
    "#             if episodes_completed >= Constants.episodes:\n",
    "#                 break\n",
    "#     except KeyboardInterrupt:\n",
    "#         print(\"========================= Stopping Evaluation =========================\")\n",
    "#         interrupted = True\n",
    "    \n",
    "#     if not interrupted:\n",
    "#         print(\"=========================Completed=========================\")\n",
    "\n",
    "#     if len(episode_metrics) > 0:\n",
    "#         print(\"Average Price Cost:\", np.mean([e['price_cost'] for e in episode_metrics]))\n",
    "#         print(\"Average Emmision Cost:\", np.mean([e['emmision_cost'] for e in episode_metrics]))\n",
    "#     print(f\"Total time taken by agent: {agent_time_elapsed}s\")\n",
    "    \n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49aa66cd-6a1c-4ea0-ab58-ce6ef886888d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmisc notes on the below\\nso not a reward in the local evaluator. uses a metrics thing instead\\n\\tdefault reward is 5 negative numbers (maybe for each building?)\\n\\tdefault obs is 5, 28\\nI don't get what the metrics thing is\\nunclear what the observations are, they are not scaled either\\n\\nin the obs_dict is the action space\\n    all teh shapes seem to be 1 (but I thought the buildings could have multiple actions?) maybe it's for different buildings?\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "misc notes on the below\n",
    "so not a reward in the local evaluator. uses a metrics thing instead\n",
    "\tdefault reward is 5 negative numbers (maybe for each building?)\n",
    "\tdefault obs is 5, 28\n",
    "I don't get what the metrics thing is\n",
    "unclear what the observations are, they are not scaled either\n",
    "\n",
    "in the obs_dict is the action space\n",
    "    all teh shapes seem to be 1 (but I thought the buildings could have multiple actions?) maybe it's for different buildings?\n",
    "    \n",
    "questions:\n",
    "differe action spaces for different buildings?\n",
    "single agent example?\n",
    "how is it for 7 buildings? how is it for the validation?\n",
    "where to line up the obs with teh obs dict?\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12d133e8-f510-4dd8-bc69-ab328a132644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (5, 28) [-3.21161405e-01 -5.17178656e-01 -3.84308580e-08 -7.27534031e-01\n",
      " -1.94652613e-01] False {}\n",
      "0 (5, 28) (5,) () {}\n",
      "obs_dict is\n",
      "{'action_space': [{'high': array([1.], dtype=float32), 'low': array([-1.], dtype=float32), 'shape': (1,), 'dtype': 'float32'}, {'high': array([1.], dtype=float32), 'low': array([-1.], dtype=float32), 'shape': (1,), 'dtype': 'float32'}, {'high': array([1.], dtype=float32), 'low': array([-1.], dtype=float32), 'shape': (1,), 'dtype': 'float32'}, {'high': array([1.], dtype=float32), 'low': array([-1.], dtype=float32), 'shape': (1,), 'dtype': 'float32'}, {'high': array([1.], dtype=float32), 'low': array([-1.], dtype=float32), 'shape': (1,), 'dtype': 'float32'}], 'observation': [[8, 1, 0, 20.0, 18.3, 22.8, 20.0, 84.0, 81.0, 68.0, 81.0, 0.0, 25.0, 964.0, 0.0, 0.0, 100.0, 815.0, 0.0, 0.1707244126403808, 2.2758, 0.0, 0.0, 2.2758, 0.22, 0.22, 0.22, 0.22], [8, 1, 0, 20.0, 18.3, 22.8, 20.0, 84.0, 81.0, 68.0, 81.0, 0.0, 25.0, 964.0, 0.0, 0.0, 100.0, 815.0, 0.0, 0.1707244126403808, 2.18875, 0.0, 0.0, 2.18875, 0.22, 0.22, 0.22, 0.22], [8, 1, 0, 20.0, 18.3, 22.8, 20.0, 84.0, 81.0, 68.0, 81.0, 0.0, 25.0, 964.0, 0.0, 0.0, 100.0, 815.0, 0.0, 0.1707244126403808, 1.0096232096354177e-07, 0.0, 0.0, 1.0096232096354177e-07, 0.22, 0.22, 0.22, 0.22], [8, 1, 0, 20.0, 18.3, 22.8, 20.0, 84.0, 81.0, 68.0, 81.0, 0.0, 25.0, 964.0, 0.0, 0.0, 100.0, 815.0, 0.0, 0.1707244126403808, 2.81915, 0.0, 0.0, 2.81915, 0.22, 0.22, 0.22, 0.22], [8, 1, 0, 20.0, 18.3, 22.8, 20.0, 84.0, 81.0, 68.0, 81.0, 0.0, 25.0, 964.0, 0.0, 0.0, 100.0, 815.0, 0.0, 0.1707244126403808, 0.7714333333333336, 0.0, 0.0, 0.7714333333333336, 0.22, 0.22, 0.22, 0.22]]}\n",
      "obs is\n",
      "[[8, 1, 1, 20.1, 19.4, 22.8, 19.4, 79.0, 79.0, 71.0, 87.0, 0.0, 201.0, 966.0, 0.0, 0.0, 444.0, 747.0, 0.0, 0.1573190581037597, 0.8511666666666671, 0.0, 0.0, 0.8511666666666671, 0.22, 0.22, 0.22, 0.22], [8, 1, 1, 20.1, 19.4, 22.8, 19.4, 79.0, 79.0, 71.0, 87.0, 0.0, 201.0, 966.0, 0.0, 0.0, 444.0, 747.0, 0.0, 0.1573190581037597, 1.3706666666666665, 0.0, 0.0, 1.3706666666666665, 0.22, 0.22, 0.22, 0.22], [8, 1, 1, 20.1, 19.4, 22.8, 19.4, 79.0, 79.0, 71.0, 87.0, 0.0, 201.0, 966.0, 0.0, 0.0, 444.0, 747.0, 0.0, 0.1573190581037597, 1.0185241699218762e-07, 0.0, 0.0, 1.0185241699218762e-07, 0.22, 0.22, 0.22, 0.22], [8, 1, 1, 20.1, 19.4, 22.8, 19.4, 79.0, 79.0, 71.0, 87.0, 0.0, 201.0, 966.0, 0.0, 0.0, 444.0, 747.0, 0.0, 0.1573190581037597, 1.9281666666666664, 0.0, 0.0, 1.9281666666666664, 0.22, 0.22, 0.22, 0.22], [8, 1, 1, 20.1, 19.4, 22.8, 19.4, 79.0, 79.0, 71.0, 87.0, 0.0, 201.0, 966.0, 0.0, 0.0, 444.0, 747.0, 0.0, 0.1573190581037597, 0.5158833333333334, 0.0, 0.0, 0.5158833333333334, 0.22, 0.22, 0.22, 0.22]]\n",
      "Episode complete: 1 | Latest episode metrics: {'price_cost': 1.0, 'emmision_cost': 1.0}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from agents.orderenforcingwrapper import OrderEnforcingAgent\n",
    "from citylearn.citylearn import CityLearnEnv\n",
    "\n",
    "class Constants:\n",
    "    episodes = 3\n",
    "    schema_path = './data/citylearn_challenge_2022_phase_1/schema.json'\n",
    "\n",
    "def action_space_to_dict(aspace):\n",
    "    \"\"\" Only for box space \"\"\"\n",
    "    return { \"high\": aspace.high,\n",
    "             \"low\": aspace.low,\n",
    "             \"shape\": aspace.shape,\n",
    "             \"dtype\": str(aspace.dtype)\n",
    "    }\n",
    "\n",
    "def env_reset(env):\n",
    "    observations = env.reset()\n",
    "    action_space = env.action_space\n",
    "    action_space_dicts = [action_space_to_dict(asp) for asp in action_space]\n",
    "    obs_dict = {\"action_space\": action_space_dicts,\n",
    "                \"observation\": observations }\n",
    "    return obs_dict\n",
    "\n",
    "\n",
    "env = CityLearnEnv(schema=Constants.schema_path)\n",
    "agent = OrderEnforcingAgent()\n",
    "\n",
    "obs_dict = env_reset(env)\n",
    "\n",
    "agent_time_elapsed = 0\n",
    "\n",
    "step_start = time.perf_counter()\n",
    "actions = agent.register_reset(obs_dict)\n",
    "agent_time_elapsed += time.perf_counter()- step_start\n",
    "\n",
    "episodes_completed = 0\n",
    "num_steps = 0\n",
    "interrupted = False\n",
    "episode_metrics = []\n",
    "\n",
    "#while True:\n",
    "for i in range(10):\n",
    "    observations, reward, done, info = env.step(actions)\n",
    "    print(i, np.shape(observations), reward, done, info)\n",
    "    print(i, np.shape(observations), np.shape(reward), np.shape(done), info)\n",
    "    print(\"obs_dict is\")\n",
    "    print(obs_dict)\n",
    "    print(\"obs is\")\n",
    "    print(observations)\n",
    "    done = True # testing stuff in the break\n",
    "    if done:\n",
    "        episodes_completed += 1\n",
    "        metrics_t = env.evaluate()\n",
    "        metrics = {\"price_cost\": metrics_t[0], \"emmision_cost\": metrics_t[1]}\n",
    "        if np.any(np.isnan(metrics_t)):\n",
    "            raise ValueError(\"Episode metrics are nan, please contant organizers\")\n",
    "        episode_metrics.append(metrics)\n",
    "        print(f\"Episode complete: {episodes_completed} | Latest episode metrics: {metrics}\", )\n",
    "\n",
    "        obs_dict = env_reset(env)\n",
    "\n",
    "        step_start = time.perf_counter()\n",
    "        actions = agent.register_reset(obs_dict)\n",
    "        agent_time_elapsed += time.perf_counter()- step_start\n",
    "        break\n",
    "    else:\n",
    "        step_start = time.perf_counter()\n",
    "        actions = agent.compute_action(observations)\n",
    "        agent_time_elapsed += time.perf_counter()- step_start\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd43b150-3fb2-4808-bad8-f7994c85377b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'price_cost': 1.0, 'emmision_cost': 1.0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a80220fa-53c7-4f72-a47e-988ad8c11af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'action_space': [{'high': array([2.], dtype=float32),\n",
       "   'low': array([-2.], dtype=float32),\n",
       "   'shape': (1,),\n",
       "   'dtype': 'float32'},\n",
       "  {'high': array([2.], dtype=float32),\n",
       "   'low': array([-2.], dtype=float32),\n",
       "   'shape': (1,),\n",
       "   'dtype': 'float32'},\n",
       "  {'high': array([2.], dtype=float32),\n",
       "   'low': array([-2.], dtype=float32),\n",
       "   'shape': (1,),\n",
       "   'dtype': 'float32'},\n",
       "  {'high': array([2.], dtype=float32),\n",
       "   'low': array([-2.], dtype=float32),\n",
       "   'shape': (1,),\n",
       "   'dtype': 'float32'},\n",
       "  {'high': array([2.], dtype=float32),\n",
       "   'low': array([-2.], dtype=float32),\n",
       "   'shape': (1,),\n",
       "   'dtype': 'float32'}],\n",
       " 'observation': [[8,\n",
       "   1,\n",
       "   0,\n",
       "   20.0,\n",
       "   18.3,\n",
       "   22.8,\n",
       "   20.0,\n",
       "   84.0,\n",
       "   81.0,\n",
       "   68.0,\n",
       "   81.0,\n",
       "   0.0,\n",
       "   25.0,\n",
       "   964.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   100.0,\n",
       "   815.0,\n",
       "   0.0,\n",
       "   0.1707244126403808,\n",
       "   2.2758,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   2.2758,\n",
       "   0.22,\n",
       "   0.22,\n",
       "   0.22,\n",
       "   0.22],\n",
       "  [8,\n",
       "   1,\n",
       "   0,\n",
       "   20.0,\n",
       "   18.3,\n",
       "   22.8,\n",
       "   20.0,\n",
       "   84.0,\n",
       "   81.0,\n",
       "   68.0,\n",
       "   81.0,\n",
       "   0.0,\n",
       "   25.0,\n",
       "   964.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   100.0,\n",
       "   815.0,\n",
       "   0.0,\n",
       "   0.1707244126403808,\n",
       "   2.18875,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   2.18875,\n",
       "   0.22,\n",
       "   0.22,\n",
       "   0.22,\n",
       "   0.22],\n",
       "  [8,\n",
       "   1,\n",
       "   0,\n",
       "   20.0,\n",
       "   18.3,\n",
       "   22.8,\n",
       "   20.0,\n",
       "   84.0,\n",
       "   81.0,\n",
       "   68.0,\n",
       "   81.0,\n",
       "   0.0,\n",
       "   25.0,\n",
       "   964.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   100.0,\n",
       "   815.0,\n",
       "   0.0,\n",
       "   0.1707244126403808,\n",
       "   1.0096232096354177e-07,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0096232096354177e-07,\n",
       "   0.22,\n",
       "   0.22,\n",
       "   0.22,\n",
       "   0.22],\n",
       "  [8,\n",
       "   1,\n",
       "   0,\n",
       "   20.0,\n",
       "   18.3,\n",
       "   22.8,\n",
       "   20.0,\n",
       "   84.0,\n",
       "   81.0,\n",
       "   68.0,\n",
       "   81.0,\n",
       "   0.0,\n",
       "   25.0,\n",
       "   964.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   100.0,\n",
       "   815.0,\n",
       "   0.0,\n",
       "   0.1707244126403808,\n",
       "   2.81915,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   2.81915,\n",
       "   0.22,\n",
       "   0.22,\n",
       "   0.22,\n",
       "   0.22],\n",
       "  [8,\n",
       "   1,\n",
       "   0,\n",
       "   20.0,\n",
       "   18.3,\n",
       "   22.8,\n",
       "   20.0,\n",
       "   84.0,\n",
       "   81.0,\n",
       "   68.0,\n",
       "   81.0,\n",
       "   0.0,\n",
       "   25.0,\n",
       "   964.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   100.0,\n",
       "   815.0,\n",
       "   0.0,\n",
       "   0.1707244126403808,\n",
       "   0.7714333333333336,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.7714333333333336,\n",
       "   0.22,\n",
       "   0.22,\n",
       "   0.22,\n",
       "   0.22]]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b8fc994-6316-4cda-ac86-645182bc706d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[8,\n",
       "  1,\n",
       "  1,\n",
       "  20.1,\n",
       "  19.4,\n",
       "  22.8,\n",
       "  19.4,\n",
       "  79.0,\n",
       "  79.0,\n",
       "  71.0,\n",
       "  87.0,\n",
       "  0.0,\n",
       "  201.0,\n",
       "  966.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  444.0,\n",
       "  747.0,\n",
       "  0.0,\n",
       "  0.1573190581037597,\n",
       "  0.8511666666666671,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.8511666666666671,\n",
       "  0.22,\n",
       "  0.22,\n",
       "  0.22,\n",
       "  0.22],\n",
       " [8,\n",
       "  1,\n",
       "  1,\n",
       "  20.1,\n",
       "  19.4,\n",
       "  22.8,\n",
       "  19.4,\n",
       "  79.0,\n",
       "  79.0,\n",
       "  71.0,\n",
       "  87.0,\n",
       "  0.0,\n",
       "  201.0,\n",
       "  966.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  444.0,\n",
       "  747.0,\n",
       "  0.0,\n",
       "  0.1573190581037597,\n",
       "  1.3706666666666665,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.3706666666666665,\n",
       "  0.22,\n",
       "  0.22,\n",
       "  0.22,\n",
       "  0.22],\n",
       " [8,\n",
       "  1,\n",
       "  1,\n",
       "  20.1,\n",
       "  19.4,\n",
       "  22.8,\n",
       "  19.4,\n",
       "  79.0,\n",
       "  79.0,\n",
       "  71.0,\n",
       "  87.0,\n",
       "  0.0,\n",
       "  201.0,\n",
       "  966.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  444.0,\n",
       "  747.0,\n",
       "  0.0,\n",
       "  0.1573190581037597,\n",
       "  1.0185241699218762e-07,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0185241699218762e-07,\n",
       "  0.22,\n",
       "  0.22,\n",
       "  0.22,\n",
       "  0.22],\n",
       " [8,\n",
       "  1,\n",
       "  1,\n",
       "  20.1,\n",
       "  19.4,\n",
       "  22.8,\n",
       "  19.4,\n",
       "  79.0,\n",
       "  79.0,\n",
       "  71.0,\n",
       "  87.0,\n",
       "  0.0,\n",
       "  201.0,\n",
       "  966.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  444.0,\n",
       "  747.0,\n",
       "  0.0,\n",
       "  0.1573190581037597,\n",
       "  1.9281666666666664,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.9281666666666664,\n",
       "  0.22,\n",
       "  0.22,\n",
       "  0.22,\n",
       "  0.22],\n",
       " [8,\n",
       "  1,\n",
       "  1,\n",
       "  20.1,\n",
       "  19.4,\n",
       "  22.8,\n",
       "  19.4,\n",
       "  79.0,\n",
       "  79.0,\n",
       "  71.0,\n",
       "  87.0,\n",
       "  0.0,\n",
       "  201.0,\n",
       "  966.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  444.0,\n",
       "  747.0,\n",
       "  0.0,\n",
       "  0.1573190581037597,\n",
       "  0.5158833333333334,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.5158833333333334,\n",
       "  0.22,\n",
       "  0.22,\n",
       "  0.22,\n",
       "  0.22]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f0e9aa-896f-495d-9f3a-d93bd9c125ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df88dfe-9d32-4408-bb1b-2cded6d1a22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Constants:\n",
    "    episodes = 3\n",
    "    schema_path = './data/citylearn_challenge_2022_phase_1/schema.json'\n",
    "\n",
    "def action_space_to_dict(aspace):\n",
    "    \"\"\" Only for box space \"\"\"\n",
    "    return { \"high\": aspace.high,\n",
    "             \"low\": aspace.low,\n",
    "             \"shape\": aspace.shape,\n",
    "             \"dtype\": str(aspace.dtype)\n",
    "    }\n",
    "\n",
    "def env_reset(env):\n",
    "    observations = env.reset()\n",
    "    action_space = env.action_space\n",
    "    action_space_dicts = [action_space_to_dict(asp) for asp in action_space]\n",
    "    obs_dict = {\"action_space\": action_space_dicts,\n",
    "                \"observation\": observations }\n",
    "    return obs_dict\n",
    "\n",
    "def evaluate():\n",
    "    print(\"Starting local evaluation\")\n",
    "    \n",
    "    env = CityLearnEnv(schema=Constants.schema_path)\n",
    "    agent = OrderEnforcingAgent()\n",
    "\n",
    "    obs_dict = env_reset(env)\n",
    "\n",
    "    agent_time_elapsed = 0\n",
    "\n",
    "    step_start = time.perf_counter()\n",
    "    actions = agent.register_reset(obs_dict)\n",
    "    agent_time_elapsed += time.perf_counter()- step_start\n",
    "\n",
    "    episodes_completed = 0\n",
    "    num_steps = 0\n",
    "    interrupted = False\n",
    "    episode_metrics = []\n",
    "    try:\n",
    "        while True:\n",
    "            observations, _, done, _ = env.step(actions)\n",
    "            if done:\n",
    "                episodes_completed += 1\n",
    "                metrics_t = env.evaluate()\n",
    "                metrics = {\"price_cost\": metrics_t[0], \"emmision_cost\": metrics_t[1]}\n",
    "                if np.any(np.isnan(metrics_t)):\n",
    "                    raise ValueError(\"Episode metrics are nan, please contant organizers\")\n",
    "                episode_metrics.append(metrics)\n",
    "                print(f\"Episode complete: {episodes_completed} | Latest episode metrics: {metrics}\", )\n",
    "\n",
    "                obs_dict = env_reset(env)\n",
    "\n",
    "                step_start = time.perf_counter()\n",
    "                actions = agent.register_reset(obs_dict)\n",
    "                agent_time_elapsed += time.perf_counter()- step_start\n",
    "            else:\n",
    "                step_start = time.perf_counter()\n",
    "                actions = agent.compute_action(observations)\n",
    "                agent_time_elapsed += time.perf_counter()- step_start\n",
    "            \n",
    "            num_steps += 1\n",
    "            if num_steps % 1000 == 0:\n",
    "                print(f\"Num Steps: {num_steps}, Num episodes: {episodes_completed}\")\n",
    "\n",
    "            if episodes_completed >= Constants.episodes:\n",
    "                break\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"========================= Stopping Evaluation =========================\")\n",
    "        interrupted = True\n",
    "    \n",
    "    if not interrupted:\n",
    "        print(\"=========================Completed=========================\")\n",
    "\n",
    "    if len(episode_metrics) > 0:\n",
    "        print(\"Average Price Cost:\", np.mean([e['price_cost'] for e in episode_metrics]))\n",
    "        print(\"Average Emmision Cost:\", np.mean([e['emmision_cost'] for e in episode_metrics]))\n",
    "    print(f\"Total time taken by agent: {agent_time_elapsed}s\")\n",
    "    \n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     evaluate()\n",
    "evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "citylearn_2022",
   "language": "python",
   "name": "citylearn_2022"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
